# JBCA Data Science Hack Night October 2017

Welcome to the 2nd JBCA Data Science Hack Night.
For this hack night, each team will choose one of the following challenges and present a 3 minute presentation.
These presentations will be judged by the organisers and the winner will win the coveted Data Monkey Trophy!

The presentations will be judged on the accuracy of the predicted results via machine learning and visualisation/presentation 
of the data/results.

## Schedule

18.00 - 18.20: Welcome presentation

18.20 - 18.30: Forming teams

18.30 - 19.15: **first half**

19.15 - 19.30: Pizza!

19.30 - 20.30: **second half**

20.30 - 20.50: Lightning presentations from teams

20.50 - 21.00: Judging and prizes


## The challenges

Below we've described two different challenges for which each team will pick one to work on.


### Challenge 1: Machine learning - Predicting whether someone will default on their loan ( folder)
Description: use data features (existing or engineered) to develop a model that can predict whether someone will default on their
loan. The data 


In the folder loan_data, you will find:
1. data in a .csv.tgz file 'loan.csv.tgz'
2. A short tutorial introducing the data, with some simple data pre processing and a very simple model 'loan_default_example.ipynb'.

Some feature engineering and editing to the data is needed to obtain a more accurate prediction.

The original source of this data is located at:
https://www.kaggle.com/wendykan/lending-club-loan-data

### Challenge 2: Machine learning - Building a Movie Recommender System

Description: Have you ever wondered how Netflix and other movie systms (Can't name another) make recommendations? Well here's your chance.
In this challenge you will design and build a simple Content-based movie recommender system movie recommender system. 

In the folder movies, you will find:
1. data in a csv file 'tmdb_5000_movies.csv'. There is an additional data file with more info
2. A short tutorial introducing the data, with some simple data pre processing and a very simple model 'Simple_Movie_Recommender.ipynb


### Challenge 3: NLP

This natural langauge processing (NLP) challenge uses a web scraping library to collect articles from the interenet, before attempting to categorise those articles using unsupervised clustering techniques. 

The challenge is open ended: once you are happy with the tools used, we would like to see what you can use NLP to show about content you find on the web.

## Helpful tools

[Pandas](https://pandas.pydata.org/) - data handling & data analysis for Python

[Matplotlib](http://matplotlib.org/) - a Python library for 2D data plotting

[Beautifulsoup](https://www.crummy.com/software/BeautifulSoup/) - Python library for webscraping

[Seaborn](https://seaborn.pydata.org/) - a Python library for visualizing statistical data - based on maptlotlib

[Bokeh](http://bokeh.pydata.org/en/latest/) - a Python library for creating interactive visualizations

[Dash](https://github.com/plotly/dash) - a Python library for creating web-based interactive dashboards

[scikit-learn](http://scikit-learn.org/stable/) - a machine learning library for Python. Part of NumPy/SciPy/matplotlib ecosystem. Thorough and straightforward.

[TensorFlow](https://www.tensorflow.org/) - powerful Python-based machine learning framework

[Jupyter Notebook](https://github.com/jupyter/notebook) - a web-based Python development environment/notebook. Very handy!
